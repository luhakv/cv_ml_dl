{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 9. Профориентация в Data Science\n",
    "### Skillfactory: DSPR-19\n",
    "### Проект 7. Возьмёте Бэтмобиль? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Чем займёмся в этом проекте?\n",
    "→ Поздравляем! Вы приступаете к выполнению финального проекта блока Профориентация, в котором вы сможете на практике поработать с задачами из всех трёх направлений — ML, CV и NLP.\n",
    "\n",
    "За основу возьмем решение, которое нам уже известно, — построенную на табличных данных модель «Предсказание стоимости автомобиля» — и добавим туда модели Deep Learning, которые будут распознавать изображения и обрабатывать текст.\n",
    "\n",
    "За последние несколько месяцев работы в компании «Старый друг» вы разработали две модели, которые уже успешно крутятся в продакшне и приносят деньги компании и радость сотрудникам (по словам Анны из отдела продаж).\n",
    "\n",
    "→ Осталось довести свою работу до логичного завершения и, обогатив датасет текстовыми данными из объявлений о продаже, свести все наши модели в единое решение — Multi-inputs сеть. Приступим?\n",
    "\n",
    "### КАК БУДЕМ РЕШАТЬ ПРОЕКТ?\n",
    "\n",
    "### ПОСТРОИМ БАЗОВОЕ РЕШЕНИЕ:\n",
    "\n",
    "- Шаг 1. Построим «наивную» ML-модель на табличных данных, которая предсказывает цену по модели и году выпуска. Это позволит нам задать направление для дальнейших экспериментов. Впоследствии на этом этапе вы можете доработать вашу модель из проекта «Выбираем авто выгодно». \n",
    "- Шаг 2. Обработаем и отнормируем признаки и сделаем первую модель на основе градиентного бустинга с помощью CatBoost.\n",
    "- Шаг 3. Решим эту же задачу с помощью DL (модель NN Tabular) и сравним результаты.\n",
    "- Шаг 4. Добавим текстовые данные (NLP) и сделаем Multi-Input нейронную сеть для анализа и табличных данных, и текста одновременно.\n",
    "- Шаг 5. Добавим обработку изображений в Multi-Input нейронную сеть.\n",
    "- Шаг 6. Осуществим ансамблирование градиентного бустинга и нейронной сети (усредним их предсказания).\n",
    "\n",
    "### САМОСТОЯТЕЛЬНАЯ ЧАСТЬ\n",
    "\n",
    "- Ознакомьтесь с критериями оценивания проекта.\n",
    "- Следуйте нашим рекомендациям, чтобы построить самую лучшую модель.\n",
    "- Задавайте вопросы одногруппникам и менторам в Slack.\n",
    "- Загрузите итоговое решение на kaggle и добавьте описание проекта на git.  \n",
    "\n",
    "На выполнение проекта отводится: две недели.\n",
    "\n",
    "### ЧТО ВЫ ПОЛУЧИТЕ В РЕЗУЛЬТАТЕ ПРОЕКТА?\n",
    "\n",
    "- Потренируетесь обрабатывать данные и оптимизировать NLP-модели.\n",
    "- Пройдетесь по всему циклу разработки комплексной Multi-Inputs модели (от обработки данных до внедрения в продакшн).\n",
    "- Увидите, как использование blend-решений влияет на целевые метрики.\n",
    "- Примерите на себя роль специалиста каждого из трёх треков второго года обучения.\n",
    "\n",
    "\n",
    "\n",
    "— Возьмете Бэтмобиль?  \n",
    "— Нет. Слишком заметно.  \n",
    "— Ну тогда возьмите Ламборгини. Это менее заметно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Начнём с простой модели\n",
    "\n",
    "Начнём с разработки baseline нашего решения и посмотрим, как происходит обращение с входящими данными и что нужно получить на выходе. \n",
    "\n",
    "По ссылке вы обнаружите baseline. \n",
    "\n",
    "СКАЧАТЬ BASELINE (https://github.com/luhakv/cv_ml_nlp/blob/master/baseline-sf-dst-car-price-part2-v6.ipynb)\n",
    "\n",
    "Итак, наша задача — предсказать стоимость автомобиля по его характеристикам, текстовому описанию или картинке. \n",
    "\n",
    "Начнём знакомиться с baseline-решением. Как видим, данные не сильно отличаются от прежних:\n",
    "\n",
    "bodyType — категориальный  \n",
    "brand —  категориальный   \n",
    "color —  категориальный  \n",
    "description —  текстовый  \n",
    "engineDisplacement — числовой, представленный как текст  \n",
    "enginePower — числовой, представленный как текст  \n",
    "fuelType — категориальный  \n",
    "mileage —  числовой   \n",
    "modelDate — числовой  \n",
    "model_info — категориальный  \n",
    "name — категориальный, желательно сократить размерность  \n",
    "numberOfDoors — категориальный  \n",
    "price — числовой, целевой  \n",
    "productionDate — числовой  \n",
    "sell_id — изображение (файл доступен по адресу, основанному на sell_id)  \n",
    "vehicleConfiguration — не используется (комбинация других столбцов)  \n",
    "vehicleTransmission — категориальный  \n",
    "Владельцы — категориальный  \n",
    "Владение — числовой, представленный как текст  \n",
    "ПТС — категориальный  \n",
    "Привод — категориальный  \n",
    "Руль — категориальный  \n",
    "\n",
    "\n",
    "Однако кое-что, скорее всего, придётся переделать, поскольку есть дополнительные столбцы. \n",
    "\n",
    "→ Переходим к построению самой простой «наивной» модели, которая предсказывает среднюю цену по модели автомобиля и году выпуска. Начинать решение всегда стоит именно с простой модели, чтобы понимать, куда вы движетесь — к улучшению или к ухудшению решения. Это сэкономит вам множество сил и ресурсов. \n",
    "\n",
    "Наша модель предсказывает среднее значение по стоимости относительно модели и года выпуска.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивная модель\n",
    "predicts = []\n",
    "for index, row in pd.DataFrame(data_test[['model_info', 'productionDate']]).iterrows():\n",
    "    query = f\"model_info == '{row[0]}' and productionDate == '{row[1]}'\"\n",
    "    predicts.append(data_train.query(query)['price'].median())\n",
    "\n",
    "# заполним не найденные совпадения\n",
    "predicts = pd.DataFrame(predicts)\n",
    "predicts = predicts.fillna(predicts.median())\n",
    "\n",
    "# округлим\n",
    "predicts = (predicts // 1000) * 1000\n",
    "\n",
    "#оцениваем точность\n",
    "print(f\"Точность наивной модели по метрике MAPE: {(mape(data_test['price'], predicts.values[:, 0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EDA и модель на основе градиентного бустинга\n",
    "\n",
    "На этом этапе нам важно посмотреть на распределение числовых признаков, опуская категориальные, поскольку задача этого шага — посмотреть, подходят ли данные для загрузки в сеть. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посмотрим, как выглядят распределения числовых признаков\n",
    "def visualize_distributions(titles_values_dict):\n",
    "  columns = min(3, len(titles_values_dict))\n",
    "  rows = (len(titles_values_dict) - 1) // columns + 1\n",
    "  fig = plt.figure(figsize = (columns * 6, rows * 4))\n",
    "  for i, (title, values) in enumerate(titles_values_dict.items()):\n",
    "    hist, bins = np.histogram(values, bins = 20)\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    ax.bar(bins[:-1], hist, width = (bins[1] - bins[0]) * 0.7)\n",
    "    ax.set_title(title)\n",
    "  plt.show()\n",
    "\n",
    "visualize_distributions({\n",
    "    'mileage': train['mileage'].dropna(),\n",
    "    'modelDate': train['modelDate'].dropna(),\n",
    "    'productionDate': train['productionDate'].dropna()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение признаков ненормальное, поэтому их необходимо нормировать. \n",
    "\n",
    "Разбиваем на категориальные признаки и числовые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#используем все текстовые признаки как категориальные без предобработки\n",
    "categorical_features = ['bodyType', 'brand', 'color', 'engineDisplacement', 'enginePower', 'fuelType', 'model_info', 'name',\n",
    "  'numberOfDoors', 'vehicleTransmission', 'Владельцы', 'Владение', 'ПТС', 'Привод', 'Руль']\n",
    "\n",
    "#используем все числовые признаки\n",
    "numerical_features = ['mileage', 'modelDate', 'productionDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем тренировочный и тестовый сеты:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sample'] = 1 # помечаем где у нас трейн\n",
    "test['sample'] = 0 # помечаем где у нас тест\n",
    "test['price'] = 0 # в тесте у нас нет значения price, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = test.append(train, sort=False).reset_index(drop=True) # объединяем\n",
    "print(train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем предобработку данных: удаляем лишнее, заполняем пропуски, если они есть, выполняем нормирование. На CatBoost это не должно повлиять. Наконец, выполняем Label Encoding или One-Hot Encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['description','sell_id',], axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # ################### Numerical Features ############################################################## \n",
    "    # Далее заполняем пропуски\n",
    "    for column in numerical_features:\n",
    "        df_output[column].fillna(df_output[column].median(), inplace=True)\n",
    "    # тут ваш код по обработке NAN\n",
    "    # ....\n",
    "    \n",
    "    # Нормализация данных\n",
    "    scaler = MinMaxScaler()\n",
    "    for column in numerical_features:\n",
    "        df_output[column] = scaler.fit_transform(df_output[[column]])[:,0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ################### Categorical Features ############################################################## \n",
    "    # Label Encoding\n",
    "    for column in categorical_features:\n",
    "        df_output[column] = df_output[column].astype('category').cat.codes\n",
    "        \n",
    "    # One-Hot Encoding: в pandas есть готовая функция - get_dummies.\n",
    "    df_output = pd.get_dummies(df_output, columns=categorical_features, dummy_na=False)\n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    df_output.drop(['vehicleConfiguration'], axis = 1, inplace=True)\n",
    "    \n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем и смотрим на чистые данные. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили целевую переменную price, дату производства, пробег, столбец с указанием принадлежности к тренировочному или тестовому наборам.   \n",
    "\n",
    "Затем выделяем тестовую часть:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.price.values     # наш таргет\n",
    "X = train_data.drop(['price'], axis=1)\n",
    "X_sub = test_data.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем запустить уже не наивную модель, а построить модель на основе градиентного бустинга при помощи CatBoost. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          #depth=10,\n",
    "                          #learning_rate = 0.5,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['RMSE', 'MAE'],\n",
    "                          od_wait=500,\n",
    "                          #task_type='GPU',\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=100,\n",
    "         use_best_model=True,\n",
    "         #plot=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем MAPE у тестовой части: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_catboost = model.predict(X_test)\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_catboost))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили MAPE 13.23%. Это неплохой результат, поскольку CatBoost хорошо работает с небольшим количеством данных и множеством категориальных признаков.\n",
    "\n",
    "Сохраняем submission: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_predict_catboost = model.predict(X_sub)\n",
    "sample_submission['price'] = sub_predict_catboost\n",
    "sample_submission.to_csv('catboost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
