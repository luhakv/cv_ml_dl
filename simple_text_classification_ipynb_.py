# -*- coding: utf-8 -*-
"""Копия блокнота "Simple text classification.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13I1shEq3c7T1KOTHuGQSUWi3AD_5U06h

# Классификация текста простыми методами

Загружем необходимые данные для nltk.
"""

import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('stopwords')

"""Мы будем использовать датасет fetch_20newsgroups. Он содержит коллекции новостей с 20 различных источников. Но мы возьмем только 4."""

from sklearn.datasets import fetch_20newsgroups
categories = ['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']
newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)
newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)

set(newsgroups_train.target)

"""Загружаем данные и таргеты"""

X_train = newsgroups_train.data
y_train = newsgroups_train.target

X_test = newsgroups_test.data
y_test = newsgroups_test.target

"""Смотрим на количество данных"""

len(X_train), len(y_train)

len(X_test), len(y_test)

"""TfidfVectorizer – это одновременно CountVectorizer после которого идет TfidfTransformer. """

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_train_vec.shape

"""Воспользуемся LogisticRegression."""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train_vec, y_train)

"""Оценим модель."""

X_test_vec = X_train_vec = vectorizer.transform(X_test)
y_pred = lr.predict(X_test_vec)

from sklearn.metrics import classification_report

print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))

"""## Предобработка данных

До этого мы не применяли предобработку. Посмотрим насколько она нам может помочь.

Рассмотрим сначала предобработку на одном примере.

Токенизируем.
"""

x = nltk.word_tokenize(x)
print(x)

"""Удалим слова со знаками препинания."""

x = [word for word in x if word.isalnum()]
print(x)

"""Лемматизируем."""

from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

def get_wordnet_pos(word):
     tag = nltk.pos_tag([word])[0][1][0].upper()
     tag_dict = {"J": wordnet.ADJ, "N": wordnet.NOUN, "V": wordnet.VERB, "R": wordnet.ADV}
     return tag_dict.get(tag, wordnet.NOUN)


lemmatizer = WordNetLemmatizer()
x = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x]
print(x)

"""Удалим стоп-слова."""

from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))
print(len(x))
x = [word for word in x if not word in stop_words]
print(x)
print(len(x))

from tqdm import tqdm

def preprocces(X):
  X_proccess = []
  lemmatizer = WordNetLemmatizer()

  for x in tqdm(X):
    
    x = x.lower()
    x = nltk.word_tokenize(x)
    x = [word for word in x if word.isalnum()]
    x = [lemmatizer.lemmatize(w) for w in x]
    x = [word for word in x if not word in stop_words]
    X_proccess.append(' '.join(x))
  return X_proccess


X_train_proc = preprocces(X_train)
X_test_proc = preprocces(X_test)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train_proc)
X_test_vec = vectorizer.transform(X_test_proc)
print(X_train_vec.shape)
print(X_test_vec.shape)

lr = LogisticRegression()
lr.fit(X_train_vec, y_train)
y_pred = lr.predict(X_test_vec)

print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))

"""## Стемминг

Воспользуемся стеммингом вместо лемматизации
"""

from nltk.stem import PorterStemmer

def preprocces(X):
  X_proccess = []
  stemmer = PorterStemmer()

  for x in tqdm(X):
    
    x = x.lower()
    x = nltk.word_tokenize(x)
    x = [word for word in x if word.isalnum()]
    x = [stemmer.stem(w) for w in x]
    x = [word for word in x if not word in stop_words]
    X_proccess.append(' '.join(x))
  return X_proccess


X_train_proc = preprocces(X_train)
X_test_proc = preprocces(X_test)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train_proc)
X_test_vec = vectorizer.transform(X_test_proc)
print(X_train_vec.shape)
print(X_test_vec.shape)

lr = LogisticRegression()
lr.fit(X_train_vec, y_train)
y_pred = lr.predict(X_test_vec)

print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))

