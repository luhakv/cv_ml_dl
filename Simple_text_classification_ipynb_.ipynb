{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Simple text classification.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1DNiHsB0bvg"
      },
      "source": [
        "# Классификация текста простыми методами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZG4CmD10mnd"
      },
      "source": [
        "Загружем необходимые данные для nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpFTvZC_j0ac",
        "outputId": "0b1e1434-5812-4c36-86e1-3fd48ffdf80a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyrc05w1EKV"
      },
      "source": [
        "Мы будем использовать датасет fetch_20newsgroups. Он содержит коллекции новостей с 20 различных источников. Но мы возьмем только 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivAOt423fyiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b6093e-7296-4c5b-a8da-3b0c9fa2691a"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6O1EiR72oCG",
        "outputId": "3560e5f3-a689-4348-bfc9-48a4dd929e52"
      },
      "source": [
        "set(newsgroups_train.target)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVH0XPGj4zc6"
      },
      "source": [
        "Загружаем данные и таргеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74KIxchqgr8A"
      },
      "source": [
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgX3xrFkibXw"
      },
      "source": [
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGtQT3YO48J-"
      },
      "source": [
        "Смотрим на количество данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0qDNIBUhfXb",
        "outputId": "6c3475b7-fa25-46ea-8616-32faa130c710"
      },
      "source": [
        "len(X_train), len(y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2373, 2373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkENH8hHtb81",
        "outputId": "71d61d57-196f-404b-84a1-75c054e08445"
      },
      "source": [
        "len(X_test), len(y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1579, 1579)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iCpZKvs2SbA"
      },
      "source": [
        "TfidfVectorizer – это одновременно CountVectorizer после которого идет TfidfTransformer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vld2k-ZAhigO",
        "outputId": "9f7f5bc8-41d0-4ff2-d912-ac59c2f4a522"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_train_vec.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2373, 38683)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9T_PY6L2U8q"
      },
      "source": [
        "Воспользуемся LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRu2fs-hysR",
        "outputId": "7af8f24e-57b1-4d07-93c3-239896476822"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train_vec, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64hdTnSs2eyC"
      },
      "source": [
        "Оценим модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl-fyhWTiINv"
      },
      "source": [
        "X_test_vec = X_train_vec = vectorizer.transform(X_test)\n",
        "y_pred = lr.predict(X_test_vec)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWgYNM7iWQ5",
        "outputId": "cb981b20-c0fd-474c-8199-99e34a867366"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.95      0.90      0.93       396\n",
            "sci.electronics       0.80      0.94      0.86       393\n",
            "        sci.med       0.95      0.87      0.91       396\n",
            "      sci.space       0.97      0.93      0.95       394\n",
            "\n",
            "       accuracy                           0.91      1579\n",
            "      macro avg       0.92      0.91      0.91      1579\n",
            "   weighted avg       0.92      0.91      0.91      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooSMdhx2_Wa"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUbPbRP35NpP"
      },
      "source": [
        "До этого мы не применяли предобработку. Посмотрим насколько она нам может помочь."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGq7Nl0zCHcv"
      },
      "source": [
        "x = X_train[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcOK5fiBCPNF",
        "outputId": "60113584-fbed-4de8-eb07-04a49c4bf0e1"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: al@escom.com (Al Donaldson)\n",
            "Subject: Re: Once tapped, your code is no good any more.\n",
            "Reply-To: al@escom.COM (Al Donaldson)\n",
            "Organization: ESCOM Corp., Oakton VA (USA)\n",
            "Distribution: na\n",
            "Lines: 16\n",
            "\n",
            "amolitor@nmsu.edu (Andrew Molitor) writes:\n",
            ">Yes, those evil guys in the FBI can probably, with some\n",
            ">effort, abuse the system. I got news for you, if the evil guys in\n",
            ">the FBI decide they want to persecute you, they're gonna, ...\n",
            "\n",
            "And if Richard Nixon had had this kind of toy, he wouldn't have had\n",
            "to send people into the Watergate.\n",
            "\n",
            "But that's not really the issue.  The real issue is whether this \n",
            "will be used to justify a ban against individuals' use of private \n",
            "(i.e., anything else) encryption methods.\n",
            "\n",
            "Unrelated question...isn't the term \"Clipper,\" as neat as it is,\n",
            "already taken by Intergraph?\n",
            "\n",
            "Al\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lg5XYRZ5Sb0"
      },
      "source": [
        "Рассмотрим сначала предобработку на одном примере.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJwt3ZhCUL8"
      },
      "source": [
        "Переведем в нижний регистр"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvHzfs1sCXnI",
        "outputId": "475b277e-823c-468f-d42a-f463ed1926a8"
      },
      "source": [
        "x = x.lower()\n",
        "print(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from: al@escom.com (al donaldson)\n",
            "subject: re: once tapped, your code is no good any more.\n",
            "reply-to: al@escom.com (al donaldson)\n",
            "organization: escom corp., oakton va (usa)\n",
            "distribution: na\n",
            "lines: 16\n",
            "\n",
            "amolitor@nmsu.edu (andrew molitor) writes:\n",
            ">yes, those evil guys in the fbi can probably, with some\n",
            ">effort, abuse the system. i got news for you, if the evil guys in\n",
            ">the fbi decide they want to persecute you, they're gonna, ...\n",
            "\n",
            "and if richard nixon had had this kind of toy, he wouldn't have had\n",
            "to send people into the watergate.\n",
            "\n",
            "but that's not really the issue.  the real issue is whether this \n",
            "will be used to justify a ban against individuals' use of private \n",
            "(i.e., anything else) encryption methods.\n",
            "\n",
            "unrelated question...isn't the term \"clipper,\" as neat as it is,\n",
            "already taken by intergraph?\n",
            "\n",
            "al\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvNKePU5xh3"
      },
      "source": [
        "Токенизируем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1irV8YFkHJw",
        "outputId": "a57f3aaa-d5ec-4ccf-f026-532523df445c"
      },
      "source": [
        "x = nltk.word_tokenize(x)\n",
        "print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'subject', ':', 're', ':', 'once', 'tapped', ',', 'your', 'code', 'is', 'no', 'good', 'any', 'more', '.', 'reply-to', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'organization', ':', 'escom', 'corp.', ',', 'oakton', 'va', '(', 'usa', ')', 'distribution', ':', 'na', 'lines', ':', '16', 'amolitor', '@', 'nmsu.edu', '(', 'andrew', 'molitor', ')', 'writes', ':', '>', 'yes', ',', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', ',', 'with', 'some', '>', 'effort', ',', 'abuse', 'the', 'system', '.', 'i', 'got', 'news', 'for', 'you', ',', 'if', 'the', 'evil', 'guys', 'in', '>', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', ',', 'they', \"'re\", 'gon', 'na', ',', '...', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', ',', 'he', 'would', \"n't\", 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', '.', 'but', 'that', \"'s\", 'not', 'really', 'the', 'issue', '.', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', \"'\", 'use', 'of', 'private', '(', 'i.e.', ',', 'anything', 'else', ')', 'encryption', 'methods', '.', 'unrelated', 'question', '...', 'is', \"n't\", 'the', 'term', '``', 'clipper', ',', \"''\", 'as', 'neat', 'as', 'it', 'is', ',', 'already', 'taken', 'by', 'intergraph', '?', 'al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQMec6l57za"
      },
      "source": [
        "Удалим слова со знаками препинания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4fp2MYNj0dD",
        "outputId": "6cda4ea5-922a-43f2-892e-bd5781131eee"
      },
      "source": [
        "x = [word for word in x if word.isalnum()]\n",
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'is', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'lines', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'got', 'news', 'for', 'you', 'if', 'the', 'evil', 'guys', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'methods', 'unrelated', 'question', 'is', 'the', 'term', 'clipper', 'as', 'neat', 'as', 'it', 'is', 'already', 'taken', 'by', 'intergraph', 'al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkBoj68q6AU5"
      },
      "source": [
        "Лемматизируем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaBPzwyrj0fb",
        "outputId": "7e5fe0d3-68ab-4b20-bcb6-2a3febffaaa1"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "     tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "     tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "     return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "x = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x]\n",
        "print(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'be', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guy', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'get', 'news', 'for', 'you', 'if', 'the', 'evil', 'guy', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'have', 'have', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'have', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'be', 'whether', 'this', 'will', 'be', 'use', 'to', 'justify', 'a', 'ban', 'against', 'individual', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'be', 'the', 'term', 'clipper', 'a', 'neat', 'a', 'it', 'be', 'already', 'take', 'by', 'intergraph', 'al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wgylucV6J1p"
      },
      "source": [
        "Удалим стоп-слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Sjl6t6lJiI",
        "outputId": "57d6e2a2-af4b-4bb0-c69c-f109a61ff965"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "print(len(x))\n",
        "x = [word for word in x if not word in stop_words]\n",
        "print(x)\n",
        "print(len(x))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "['al', 'al', 'donaldson', 'subject', 'tapped', 'code', 'good', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'evil', 'guy', 'fbi', 'probably', 'effort', 'abuse', 'system', 'get', 'news', 'evil', 'guy', 'fbi', 'decide', 'want', 'persecute', 'gon', 'na', 'richard', 'nixon', 'kind', 'toy', 'would', 'send', 'people', 'watergate', 'really', 'issue', 'real', 'issue', 'whether', 'use', 'justify', 'ban', 'individual', 'use', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'term', 'clipper', 'neat', 'already', 'take', 'intergraph', 'al']\n",
            "73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFflSZDLBpiZ",
        "outputId": "e0d09b77-a679-429c-850d-991f14793d92"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [lemmatizer.lemmatize(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:10<00:00, 234.29it/s]\n",
            "100%|██████████| 1579/1579 [00:05<00:00, 273.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEJ_VN2xB1s-",
        "outputId": "ea7d472d-c6ca-4dd8-816f-9631f3cb6413"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2373, 29333)\n",
            "(1579, 29333)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hsMuhYAB3-B",
        "outputId": "bdcfd108-5a5e-4ad8-c731-160894327e2f"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.98      0.92      0.95       396\n",
            "sci.electronics       0.85      0.97      0.90       393\n",
            "        sci.med       0.96      0.92      0.94       396\n",
            "      sci.space       0.98      0.95      0.97       394\n",
            "\n",
            "       accuracy                           0.94      1579\n",
            "      macro avg       0.94      0.94      0.94      1579\n",
            "   weighted avg       0.94      0.94      0.94      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv4KdGEF3pi9"
      },
      "source": [
        "## Стемминг "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAoIILi7S0b"
      },
      "source": [
        "Воспользуемся стеммингом вместо лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLDlk5ZvsoFl",
        "outputId": "58c37928-6732-4876-aca9-d743d14ea902"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [stemmer.stem(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:20<00:00, 113.69it/s]\n",
            "100%|██████████| 1579/1579 [00:12<00:00, 131.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0yyJKxgvpZZ",
        "outputId": "bb42542a-4fab-4038-ccbf-ab686db1c8dc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2373, 23978)\n",
            "(1579, 23978)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8INNKEovp6x",
        "outputId": "a803d9e6-51b3-4ffc-eb38-77a998c0731d"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.96      0.92      0.94       396\n",
            "sci.electronics       0.84      0.95      0.89       393\n",
            "        sci.med       0.95      0.91      0.93       396\n",
            "      sci.space       0.99      0.94      0.96       394\n",
            "\n",
            "       accuracy                           0.93      1579\n",
            "      macro avg       0.94      0.93      0.93      1579\n",
            "   weighted avg       0.94      0.93      0.93      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oohUi82MB_c0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}