{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Simple text classification.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1DNiHsB0bvg"
      },
      "source": [
        "# Классификация текста простыми методами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZG4CmD10mnd"
      },
      "source": [
        "Загружем необходимые данные для nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpFTvZC_j0ac",
        "outputId": "52a3ae05-81e9-4cf6-b1c2-5ac0c4bc1071"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyrc05w1EKV"
      },
      "source": [
        "Мы будем использовать датасет fetch_20newsgroups. Он содержит коллекции новостей с 20 различных источников. Но мы возьмем только 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivAOt423fyiv"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6O1EiR72oCG",
        "outputId": "b2d40cdf-914e-4a6f-b340-342adf393a97"
      },
      "source": [
        "set(newsgroups_train.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVH0XPGj4zc6"
      },
      "source": [
        "Загружаем данные и таргеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74KIxchqgr8A"
      },
      "source": [
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgX3xrFkibXw"
      },
      "source": [
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGtQT3YO48J-"
      },
      "source": [
        "Смотрим на количество данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0qDNIBUhfXb",
        "outputId": "9fff80c6-e848-49d7-8916-4350cfa4cc0b"
      },
      "source": [
        "len(X_train), len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2373, 2373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkENH8hHtb81",
        "outputId": "0153affc-483e-4778-b3e5-4c422b48ca77"
      },
      "source": [
        "len(X_test), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1579, 1579)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iCpZKvs2SbA"
      },
      "source": [
        "TfidfVectorizer – это одновременно CountVectorizer после которого идет TfidfTransformer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vld2k-ZAhigO",
        "outputId": "bc7edfcd-2eb8-482d-81cf-79fac4ced804"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_train_vec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2373, 38683)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9T_PY6L2U8q"
      },
      "source": [
        "Воспользуемся LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRu2fs-hysR",
        "outputId": "d979a261-7f7c-4573-efb4-9b6e41dd2410"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64hdTnSs2eyC"
      },
      "source": [
        "Оценим модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl-fyhWTiINv"
      },
      "source": [
        "X_test_vec = X_train_vec = vectorizer.transform(X_test)\n",
        "y_pred = lr.predict(X_test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWgYNM7iWQ5",
        "outputId": "6433abe6-e07a-4644-bf44-61aaa2479814"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.95      0.90      0.93       396\n",
            "sci.electronics       0.80      0.94      0.86       393\n",
            "        sci.med       0.95      0.87      0.91       396\n",
            "      sci.space       0.97      0.93      0.95       394\n",
            "\n",
            "       accuracy                           0.91      1579\n",
            "      macro avg       0.92      0.91      0.91      1579\n",
            "   weighted avg       0.92      0.91      0.91      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooSMdhx2_Wa"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUbPbRP35NpP"
      },
      "source": [
        "До этого мы не применяли предобработку. Посмотрим насколько она нам может помочь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lg5XYRZ5Sb0"
      },
      "source": [
        "Рассмотрим сначала предобработку на одном примере.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvNKePU5xh3"
      },
      "source": [
        "Токенизируем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1irV8YFkHJw",
        "outputId": "4b470a04-8940-47cb-8ed3-f61a3fc4aa22"
      },
      "source": [
        "x = nltk.word_tokenize(x)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From', ':', 'al', '@', 'escom.com', '(', 'Al', 'Donaldson', ')', 'Subject', ':', 'Re', ':', 'Once', 'tapped', ',', 'your', 'code', 'is', 'no', 'good', 'any', 'more', '.', 'Reply-To', ':', 'al', '@', 'escom.COM', '(', 'Al', 'Donaldson', ')', 'Organization', ':', 'ESCOM', 'Corp.', ',', 'Oakton', 'VA', '(', 'USA', ')', 'Distribution', ':', 'na', 'Lines', ':', '16', 'amolitor', '@', 'nmsu.edu', '(', 'Andrew', 'Molitor', ')', 'writes', ':', '>', 'Yes', ',', 'those', 'evil', 'guys', 'in', 'the', 'FBI', 'can', 'probably', ',', 'with', 'some', '>', 'effort', ',', 'abuse', 'the', 'system', '.', 'I', 'got', 'news', 'for', 'you', ',', 'if', 'the', 'evil', 'guys', 'in', '>', 'the', 'FBI', 'decide', 'they', 'want', 'to', 'persecute', 'you', ',', 'they', \"'re\", 'gon', 'na', ',', '...', 'And', 'if', 'Richard', 'Nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', ',', 'he', 'would', \"n't\", 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'Watergate', '.', 'But', 'that', \"'s\", 'not', 'really', 'the', 'issue', '.', 'The', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', \"'\", 'use', 'of', 'private', '(', 'i.e.', ',', 'anything', 'else', ')', 'encryption', 'methods', '.', 'Unrelated', 'question', '...', 'is', \"n't\", 'the', 'term', '``', 'Clipper', ',', \"''\", 'as', 'neat', 'as', 'it', 'is', ',', 'already', 'taken', 'by', 'Intergraph', '?', 'Al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQMec6l57za"
      },
      "source": [
        "Удалим слова со знаками препинания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4fp2MYNj0dD",
        "outputId": "a340c598-dd94-4590-dc83-d00254c391c1"
      },
      "source": [
        "x = [word for word in x if word.isalnum()]\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From', 'al', 'Al', 'Donaldson', 'Subject', 'Re', 'Once', 'tapped', 'your', 'code', 'is', 'no', 'good', 'any', 'more', 'al', 'Al', 'Donaldson', 'Organization', 'ESCOM', 'Oakton', 'VA', 'USA', 'Distribution', 'na', 'Lines', '16', 'amolitor', 'Andrew', 'Molitor', 'writes', 'Yes', 'those', 'evil', 'guys', 'in', 'the', 'FBI', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'I', 'got', 'news', 'for', 'you', 'if', 'the', 'evil', 'guys', 'in', 'the', 'FBI', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'And', 'if', 'Richard', 'Nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'Watergate', 'But', 'that', 'not', 'really', 'the', 'issue', 'The', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'methods', 'Unrelated', 'question', 'is', 'the', 'term', 'Clipper', 'as', 'neat', 'as', 'it', 'is', 'already', 'taken', 'by', 'Intergraph', 'Al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkBoj68q6AU5"
      },
      "source": [
        "Лемматизируем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaBPzwyrj0fb",
        "outputId": "0d332e3b-85c9-41af-f8b6-489d383b9b4b"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "     tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "     tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "     return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "x = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x]\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From', 'al', 'Al', 'Donaldson', 'Subject', 'Re', 'Once', 'tapped', 'your', 'code', 'be', 'no', 'good', 'any', 'more', 'al', 'Al', 'Donaldson', 'Organization', 'ESCOM', 'Oakton', 'VA', 'USA', 'Distribution', 'na', 'Lines', '16', 'amolitor', 'Andrew', 'Molitor', 'writes', 'Yes', 'those', 'evil', 'guy', 'in', 'the', 'FBI', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'I', 'get', 'news', 'for', 'you', 'if', 'the', 'evil', 'guy', 'in', 'the', 'FBI', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'And', 'if', 'Richard', 'Nixon', 'have', 'have', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'have', 'to', 'send', 'people', 'into', 'the', 'Watergate', 'But', 'that', 'not', 'really', 'the', 'issue', 'The', 'real', 'issue', 'be', 'whether', 'this', 'will', 'be', 'use', 'to', 'justify', 'a', 'ban', 'against', 'individual', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'method', 'Unrelated', 'question', 'be', 'the', 'term', 'Clipper', 'a', 'neat', 'a', 'it', 'be', 'already', 'take', 'by', 'Intergraph', 'Al']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wgylucV6J1p"
      },
      "source": [
        "Удалим стоп-слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Sjl6t6lJiI",
        "outputId": "f12e2c62-da99-4055-835e-71b76d227835"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "print(len(x))\n",
        "x = [word for word in x if not word in stop_words]\n",
        "print(x)\n",
        "print(len(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "['From', 'al', 'Al', 'Donaldson', 'Subject', 'Re', 'Once', 'tapped', 'code', 'good', 'al', 'Al', 'Donaldson', 'Organization', 'ESCOM', 'Oakton', 'VA', 'USA', 'Distribution', 'na', 'Lines', '16', 'amolitor', 'Andrew', 'Molitor', 'writes', 'Yes', 'evil', 'guy', 'FBI', 'probably', 'effort', 'abuse', 'system', 'I', 'get', 'news', 'evil', 'guy', 'FBI', 'decide', 'want', 'persecute', 'gon', 'na', 'And', 'Richard', 'Nixon', 'kind', 'toy', 'would', 'send', 'people', 'Watergate', 'But', 'really', 'issue', 'The', 'real', 'issue', 'whether', 'use', 'justify', 'ban', 'individual', 'use', 'private', 'anything', 'else', 'encryption', 'method', 'Unrelated', 'question', 'term', 'Clipper', 'neat', 'already', 'take', 'Intergraph', 'Al']\n",
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFflSZDLBpiZ",
        "outputId": "4cd949e8-d609-4284-db37-7841270963a8"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [lemmatizer.lemmatize(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:09<00:00, 242.91it/s]\n",
            "100%|██████████| 1579/1579 [00:05<00:00, 276.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEJ_VN2xB1s-",
        "outputId": "2c7a889d-ca8b-41fb-960d-df4820984899"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2373, 29333)\n",
            "(1579, 29333)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hsMuhYAB3-B",
        "outputId": "e38e152b-1e2e-4705-f801-5bd7bcfb7b47"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.98      0.92      0.95       396\n",
            "sci.electronics       0.85      0.97      0.90       393\n",
            "        sci.med       0.96      0.92      0.94       396\n",
            "      sci.space       0.98      0.95      0.97       394\n",
            "\n",
            "       accuracy                           0.94      1579\n",
            "      macro avg       0.94      0.94      0.94      1579\n",
            "   weighted avg       0.94      0.94      0.94      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv4KdGEF3pi9"
      },
      "source": [
        "## Стемминг "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAoIILi7S0b"
      },
      "source": [
        "Воспользуемся стеммингом вместо лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLDlk5ZvsoFl",
        "outputId": "72e2d1fe-192a-46f3-8369-9752afb9f304"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [stemmer.stem(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:20<00:00, 118.62it/s]\n",
            "100%|██████████| 1579/1579 [00:11<00:00, 137.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0yyJKxgvpZZ",
        "outputId": "2cd0ae90-50e2-40e7-dec6-695e5596b604"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2373, 23978)\n",
            "(1579, 23978)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8INNKEovp6x",
        "outputId": "02fa890a-6212-48a1-ceea-99b4085da8fb"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.96      0.92      0.94       396\n",
            "sci.electronics       0.84      0.95      0.89       393\n",
            "        sci.med       0.95      0.91      0.93       396\n",
            "      sci.space       0.99      0.94      0.96       394\n",
            "\n",
            "       accuracy                           0.93      1579\n",
            "      macro avg       0.94      0.93      0.93      1579\n",
            "   weighted avg       0.94      0.93      0.93      1579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oohUi82MB_c0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}