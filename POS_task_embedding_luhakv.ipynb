{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_task_embedding_luhakv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsP7cV1_arhs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchtext import datasets\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import random\n",
        "\n",
        "from gensim.models import FastText\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRfW260a3jg"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyk3BCHza5ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a3b182-3a3a-4cca-f80b-59069c724935"
      },
      "source": [
        "train_data, _, test_data = datasets.UDPOS()\n",
        "train_data = [d for d in train_data]\n",
        "test_data = [d for d in test_data]\n",
        "\n",
        "train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n",
        "train_tags = [ d[1] for d in train_data]\n",
        "\n",
        "test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n",
        "test_tags = [d[1] for d in test_data]\n",
        "\n",
        "tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 1.88MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDDAUdhbxCq"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "word_to_ix = {}\n",
        "for tokens in train_tokens:\n",
        "    for word in tokens:\n",
        "        word = stemmer.stem(word)\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "word_to_ix[\"UNK\"] =  len(word_to_ix)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hkWDYVab5PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5aed2d5-97b0-4fb4-9a88-a26d19ebfe4c"
      },
      "source": [
        "max_len = 20\n",
        "pad_inds = len(tag2num)\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(w) for w in seq]\n",
        "    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n",
        "    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n",
        "    \n",
        "    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n",
        "    all_tags = [tags[:max_len] for tags in all_tags]\n",
        "    \n",
        "    all_ids = []\n",
        "    for tokens in all_tokens:\n",
        "        ids = prepare_sequence(tokens, word_to_ix)\n",
        "        all_ids.append(ids)\n",
        "        \n",
        "    X_vecs = []\n",
        "    Y_vecs = []\n",
        "\n",
        "    for ids, tags in zip(all_ids, all_tags):\n",
        "        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n",
        "        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n",
        "        \n",
        "    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n",
        "    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n",
        "\n",
        "    # в качестве заполнителя Y используем pad_tags\n",
        "    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "\n",
        "X_train.size(), Y_train.size()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12543, 20]), torch.Size([12543, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYNHAQxZcHhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff324ad-76f9-4080-9c09-752d405f197b"
      },
      "source": [
        "X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "\n",
        "X_test.size(), Y_test.size()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2077, 20]), torch.Size([2077, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeBb8AbNcdX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf56119-c1c5-4949-f691-d6e378fac323"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,  ...,    14,    15,    11],\n",
            "        [   23,    24,     6,  ...,    37, 12121, 12121],\n",
            "        [   38,     3,    39,  ..., 12121, 12121, 12121],\n",
            "        ...,\n",
            "        [ 3083,    43,    28,  ...,   211,    29,    25],\n",
            "        [   11,  4206,    13,  ...,    17,   368,    42],\n",
            "        [  112,    28,   387,  ...,   132,    43,  1054]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfjixGEdceuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c63da01-4ee1-4e61-c0fc-937346ce30f5"
      },
      "source": [
        "print(Y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[11, 12, 11,  ...,  7,  1,  5],\n",
            "        [12,  5,  7,  ..., 12, 17, 17],\n",
            "        [11, 12,  0,  ..., 17, 17, 17],\n",
            "        ...,\n",
            "        [ 2, 10,  3,  ...,  2,  3,  5],\n",
            "        [ 5,  7,  1,  ...,  1,  7, 10],\n",
            "        [10,  3,  2,  ...,  7, 10,  2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8RSqbmOckWA"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "bs = 128\n",
        "data = TensorDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5lgGR7Dcl0X"
      },
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # padding_idx=pad_idx - это номер id \"заполнителя\". \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        outputs, (hidden, cell) = self.lstm(self.embedding(text))\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        return predictions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHtLZSe8dBWV"
      },
      "source": [
        "def train_on_epoch(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input)  \n",
        "\n",
        "        # outputs = [batch size, sent len, out dim]\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        # outputs = [batch size * sent len, out dim]\n",
        "\n",
        "        # b_tags = [batch size, sent len]\n",
        "        b_tags = b_tags.view(-1)\n",
        "        # b_tags = [batch size * sent len]\n",
        "        \n",
        "        loss = criterion(outputs, b_tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def predict_on_dataloader(model, dataloaded):\n",
        "    model.eval()\n",
        "        \n",
        "    all_outputs = []\n",
        "    all_tags = []\n",
        "    for batch in dataloaded:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        outputs = model(b_input)  \n",
        "        \n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        b_tags = b_tags.view(-1)\n",
        "\n",
        "        all_outputs.append(outputs)\n",
        "        all_tags.append(b_tags)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs)\n",
        "    all_tags = torch.cat(all_tags)\n",
        "    \n",
        "    return all_outputs, all_tags"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9HPx3ywdDUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fedc95-7b62-4605-dcfc-fbd652888261"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uDf2IvsdEeg"
      },
      "source": [
        "INPUT_DIM = len(word_to_ix)+1\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(tag2num)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = len(word_to_ix)\n",
        "\n",
        "model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWu61Ea-dKbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d7279a-472d-4369-e26c-8e740e55b204"
      },
      "source": [
        "epochs = 50\n",
        "for e in range(epochs):\n",
        "    train_on_epoch(model, dataloader, optimizer)    \n",
        "    \n",
        "    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n",
        "    loss = criterion(all_outputs, all_tags).item()\n",
        "    all_outputs = all_outputs.detach().cpu().numpy()\n",
        "    all_tags = all_tags.detach().cpu().numpy()\n",
        "    \n",
        "    mask = all_tags != pad_inds\n",
        "    loss = loss/len(all_tags[mask]) \n",
        "    all_tags = all_tags[mask]\n",
        "    all_preds = np.argmax(all_outputs, axis=1)[mask]\n",
        "    \n",
        "    print(f\"{e}:\\tLoss {loss}, \"\n",
        "          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n",
        "          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tLoss 5.555607670967034e-06, accuracy: 0.7132111908583799, f1-macro: 0.5308734552551728\n",
            "1:\tLoss 3.622419984566319e-06, accuracy: 0.8062264371421367, f1-macro: 0.7012853704301303\n",
            "2:\tLoss 2.7358180769227527e-06, accuracy: 0.8539579451035382, f1-macro: 0.7661354255357458\n",
            "3:\tLoss 2.1689775275324235e-06, accuracy: 0.8846288676912858, f1-macro: 0.8110273001066267\n",
            "4:\tLoss 1.7580272616236363e-06, accuracy: 0.9073722147395094, f1-macro: 0.8487488031659095\n",
            "5:\tLoss 1.4469004882973161e-06, accuracy: 0.924094540489677, f1-macro: 0.8740438964413283\n",
            "6:\tLoss 1.1804720664466153e-06, accuracy: 0.9389472130482113, f1-macro: 0.9012843455057419\n",
            "7:\tLoss 9.72007848370734e-07, accuracy: 0.9506817468956992, f1-macro: 0.9199511268916443\n",
            "8:\tLoss 7.926807034522048e-07, accuracy: 0.9601714668782327, f1-macro: 0.9344897129866977\n",
            "9:\tLoss 6.455047358288925e-07, accuracy: 0.9682712473169862, f1-macro: 0.9472012215814047\n",
            "10:\tLoss 5.351424637323649e-07, accuracy: 0.9745075247390789, f1-macro: 0.9566971116807137\n",
            "11:\tLoss 4.436909938719749e-07, accuracy: 0.9791570570182722, f1-macro: 0.9627544191146976\n",
            "12:\tLoss 3.6021708482434865e-07, accuracy: 0.9835236812487316, f1-macro: 0.9707099124782375\n",
            "13:\tLoss 2.852370172809229e-07, accuracy: 0.9872937385068605, f1-macro: 0.975829709580685\n",
            "14:\tLoss 2.211074130416662e-07, accuracy: 0.9905717817671913, f1-macro: 0.9819192539091356\n",
            "15:\tLoss 1.747057179011311e-07, accuracy: 0.9927981451072283, f1-macro: 0.9853262339929953\n",
            "16:\tLoss 1.4681943518434036e-07, accuracy: 0.9941942348259808, f1-macro: 0.9883249503386076\n",
            "17:\tLoss 1.3206638335988087e-07, accuracy: 0.9947969519732837, f1-macro: 0.9908462199849052\n",
            "18:\tLoss 1.2179518360064812e-07, accuracy: 0.9951413617717424, f1-macro: 0.9918406730802871\n",
            "19:\tLoss 1.040395977878387e-07, accuracy: 0.9957010276942379, f1-macro: 0.9933694359958892\n",
            "20:\tLoss 8.599493007105293e-08, accuracy: 0.9964759497407701, f1-macro: 0.9942776317131576\n",
            "21:\tLoss 6.751379851109493e-08, accuracy: 0.9975276296610639, f1-macro: 0.9953008168968523\n",
            "22:\tLoss 5.555764704243821e-08, accuracy: 0.9979396913842199, f1-macro: 0.9968815620096391\n",
            "23:\tLoss 5.059975205822239e-08, accuracy: 0.998056544708697, f1-macro: 0.9966437351413174\n",
            "24:\tLoss 3.633002031857329e-08, accuracy: 0.9988068660553393, f1-macro: 0.9980629466102178\n",
            "25:\tLoss 2.793985766406323e-08, accuracy: 0.999151275853798, f1-macro: 0.9986903025035098\n",
            "26:\tLoss 2.4122799469335076e-08, accuracy: 0.9991697263787155, f1-macro: 0.9985180292954474\n",
            "27:\tLoss 2.1404564674642104e-08, accuracy: 0.9992496786533577, f1-macro: 0.9986103835071928\n",
            "28:\tLoss 1.7405749168284674e-08, accuracy: 0.9995202863521467, f1-macro: 0.9992338101160878\n",
            "29:\tLoss 1.688098131395478e-08, accuracy: 0.9995264365271191, f1-macro: 0.9994040240439451\n",
            "30:\tLoss 1.3059718916382986e-08, accuracy: 0.9996986414263486, f1-macro: 0.9994117991387438\n",
            "31:\tLoss 1.2053836179006734e-08, accuracy: 0.9996740407264587, f1-macro: 0.999576875751944\n",
            "32:\tLoss 1.1123760832142214e-08, accuracy: 0.999692491251376, f1-macro: 0.9995248586343713\n",
            "33:\tLoss 1.0090484190644606e-08, accuracy: 0.999741692651156, f1-macro: 0.9997031271024468\n",
            "34:\tLoss 1.1426991826138334e-08, accuracy: 0.9996863410764036, f1-macro: 0.9996229893706505\n",
            "35:\tLoss 1.0712448460648179e-08, accuracy: 0.9996678905514862, f1-macro: 0.9994828717531182\n",
            "36:\tLoss 8.98779524375097e-09, accuracy: 0.999717091951266, f1-macro: 0.9997010170162388\n",
            "37:\tLoss 7.016100719364638e-09, accuracy: 0.9998031944008807, f1-macro: 0.9997821068692891\n",
            "38:\tLoss 8.053157706743451e-09, accuracy: 0.9997539930011009, f1-macro: 0.9997051957147515\n",
            "39:\tLoss 9.1598446557963e-09, accuracy: 0.9996740407264587, f1-macro: 0.9995990670109913\n",
            "40:\tLoss 1.0272709749661441e-08, accuracy: 0.9996371396766238, f1-macro: 0.9995994347656638\n",
            "41:\tLoss 7.236267920291071e-09, accuracy: 0.9997539930011009, f1-macro: 0.9997078855894176\n",
            "42:\tLoss 7.433519638211097e-09, accuracy: 0.999717091951266, f1-macro: 0.9996534050120417\n",
            "43:\tLoss 6.248056151985655e-09, accuracy: 0.9997970442259082, f1-macro: 0.9996982963944911\n",
            "44:\tLoss 7.173554273240603e-09, accuracy: 0.9997109417762935, f1-macro: 0.9996277453775401\n",
            "45:\tLoss 6.358342731247607e-09, accuracy: 0.9997478428261284, f1-macro: 0.9996955769022184\n",
            "46:\tLoss 6.243760304393377e-09, accuracy: 0.9997908940509358, f1-macro: 0.9997789327892389\n",
            "47:\tLoss 7.2510148491007625e-09, accuracy: 0.9997478428261284, f1-macro: 0.9996540340231749\n",
            "48:\tLoss 6.314330340715523e-09, accuracy: 0.9997601431760733, f1-macro: 0.9997000370108989\n",
            "49:\tLoss 8.868254692800654e-09, accuracy: 0.999717091951266, f1-macro: 0.9996160632847454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kcXubKVdVov"
      },
      "source": [
        "def count_metrics(model, dataloader):\n",
        "  y_pred, y_true = predict_on_dataloader(model, dataloader)\n",
        "\n",
        "  y_pred = y_pred.detach().cpu().numpy()\n",
        "  y_true = y_true.detach().cpu().numpy()\n",
        "\n",
        "  mask = y_true != pad_inds\n",
        "  y_true = y_true[mask]\n",
        "  y_pred = np.argmax(y_pred, axis=1)[mask]\n",
        "\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25kR8EZsdavw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84792055-b307-4ee4-db24-fa8aa8def6aa"
      },
      "source": [
        "count_metrics(model, dataloader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      9962\n",
            "           1       1.00      1.00      1.00     13578\n",
            "           2       1.00      1.00      1.00      8547\n",
            "           3       1.00      1.00      1.00     10404\n",
            "           4       1.00      1.00      1.00      5202\n",
            "           5       1.00      1.00      1.00     13014\n",
            "           6       1.00      1.00      1.00       649\n",
            "           7       1.00      1.00      1.00     27080\n",
            "           8       1.00      1.00      1.00      3339\n",
            "           9       1.00      1.00      1.00      4484\n",
            "          10       1.00      1.00      1.00     15619\n",
            "          11       1.00      1.00      1.00     10523\n",
            "          12       1.00      1.00      1.00     16990\n",
            "          13       1.00      1.00      1.00      3134\n",
            "          14       1.00      1.00      1.00       484\n",
            "          15       1.00      1.00      1.00     18849\n",
            "          16       1.00      1.00      1.00       739\n",
            "\n",
            "    accuracy                           1.00    162597\n",
            "   macro avg       1.00      1.00      1.00    162597\n",
            "weighted avg       1.00      1.00      1.00    162597\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAOUiigWdY7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2cd270-ffad-45df-e579-0bf181adc662"
      },
      "source": [
        "data = TensorDataset(X_test, Y_test)\n",
        "test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n",
        "count_metrics(model, test_dataloader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82      1466\n",
            "           1       0.92      0.97      0.94      1656\n",
            "           2       0.88      0.85      0.86      1066\n",
            "           3       0.97      0.98      0.97      1336\n",
            "           4       0.99      0.99      0.99       599\n",
            "           5       0.98      0.99      0.99      1607\n",
            "           6       0.94      0.77      0.85       115\n",
            "           7       0.83      0.87      0.85      3446\n",
            "           8       0.86      0.71      0.78       448\n",
            "           9       0.95      0.96      0.95       546\n",
            "          10       0.98      0.99      0.98      1923\n",
            "          11       0.77      0.69      0.72      1773\n",
            "          12       0.99      0.99      0.99      2467\n",
            "          13       0.91      0.81      0.86       330\n",
            "          14       0.75      0.75      0.75        81\n",
            "          15       0.91      0.89      0.90      2306\n",
            "          16       0.33      0.36      0.34       114\n",
            "\n",
            "    accuracy                           0.90     21279\n",
            "   macro avg       0.87      0.85      0.86     21279\n",
            "weighted avg       0.90      0.90      0.90     21279\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W32kZg1qdbSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}